{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1485833b-cee5-4722-91bd-12cb0c46fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.sparse import hstack, csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "021852c1-5b7a-4fc3-8f42-80aa437df210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df = pd.read_csv(\"final_ML_fall25/csv_files/engagement_reddit.csv\")\n",
    "\n",
    "df = pd.read_csv(\"../../csv_files/engagement_reddit.csv\")\n",
    "TEXT_COL = \"text_clean\"\n",
    "LABEL_COL = \"high_engagement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5297841-32d3-4c0b-a03d-89e90922a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89      1073\n",
      "           1       0.67      0.75      0.71       368\n",
      "\n",
      "    accuracy                           0.84      1441\n",
      "   macro avg       0.79      0.81      0.80      1441\n",
      "weighted avg       0.85      0.84      0.84      1441\n",
      "\n",
      "Confusion Matrix:\n",
      "[[936 137]\n",
      " [ 93 275]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_model = df[[TEXT_COL, LABEL_COL]].dropna().copy()\n",
    "\n",
    "\n",
    "X_train_df, X_test_df = train_test_split(\n",
    "    df_model,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_model[LABEL_COL]\n",
    ")\n",
    "\n",
    "y_train = X_train_df[LABEL_COL].values\n",
    "y_test  = X_test_df[LABEL_COL].values\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=8000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(X_train_df[TEXT_COL])\n",
    "X_test  = tfidf.transform(X_test_df[TEXT_COL])\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"liblinear\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ead9089b-f1be-48bf-b685-1afde8f72c8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 8001 features, but LogisticRegression is expecting 8000 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 59\u001b[0m\n\u001b[1;32m     44\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     45\u001b[0m     LogisticRegression(\n\u001b[1;32m     46\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     57\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 59\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlog_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n",
      "File \u001b[0;32m/opt/pub/envs/CSC371-shared/lib/python3.10/site-packages/sklearn/linear_model/_base.py:375\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 375\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    377\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, indexing_dtype(xp))\n",
      "File \u001b[0;32m/opt/pub/envs/CSC371-shared/lib/python3.10/site-packages/sklearn/linear_model/_base.py:352\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    349\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 352\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    355\u001b[0m     xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (scores\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m scores\n\u001b[1;32m    358\u001b[0m )\n",
      "File \u001b[0;32m/opt/pub/envs/CSC371-shared/lib/python3.10/site-packages/sklearn/utils/validation.py:2975\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2972\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 2975\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/pub/envs/CSC371-shared/lib/python3.10/site-packages/sklearn/utils/validation.py:2839\u001b[0m, in \u001b[0;36m_check_n_features\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m-> 2839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2841\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2842\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 8001 features, but LogisticRegression is expecting 8000 features as input."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"../../csv_files/engagement_reddit.csv\")\n",
    "\n",
    "TEXT_COL = \"text_clean\"\n",
    "LABEL_COL = \"high_engagement\"  # already in your CSV\n",
    "\n",
    "\n",
    "df_model = df[[TEXT_COL, LABEL_COL]].dropna().copy()\n",
    "df_model[\"post_length\"] = df_model[TEXT_COL].str.split().str.len()\n",
    "\n",
    "\n",
    "X_train_df, X_test_df = train_test_split(\n",
    "    df_model,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_model[LABEL_COL]\n",
    ")\n",
    "\n",
    "y_train = X_train_df[LABEL_COL].values\n",
    "y_test  = X_test_df[LABEL_COL].values\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=8000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "\n",
    "X_train_text = tfidf.fit_transform(X_train_df[TEXT_COL])\n",
    "X_test_text  = tfidf.transform(X_test_df[TEXT_COL])\n",
    "\n",
    "X_train_num = csr_matrix(X_train_df[[\"post_length\"]].values)\n",
    "X_test_num  = csr_matrix(X_test_df[[\"post_length\"]].values)\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "X_test_num  = scaler.transform(X_test_num)\n",
    "\n",
    "X_train = hstack([X_train_text, X_train_num])\n",
    "X_test  = hstack([X_test_text, X_test_num])\n",
    "\n",
    "param_grid = {\"C\": [0.01, 0.1, 0.5, 1, 5, 10]}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        solver=\"liblinear\",\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    ),\n",
    "    param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b03232-3842-4068-a7ca-cac040fa4d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (CSC371)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
